<!DOCTYPE html>
<html lang='en'>

<head>
    <base href="..">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=default">
    </script>
    <meta name="description" content="Conference Template">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>UDM-KDD’24 - Schedule</title>
</head>

<body>

    <div class="banner">
        <img src="assets/banner-2.jpg" alt="UDM-KDD’24", width="1000" height="500">
        <div class="centered">
            3rd Workshop on Uncertainty Reasoning and Quantification in Decision Making <br>
            (held in conjunction with ACM SIGKDD'24)<br> 
            August 26, 2024, Barcelona, Spain
        </div>
    </div>

    <table class="navigation">
        <tr>
            <td class="navigation">
                <a title="Workshop Home Page" href=".">Home</a>
            </td>
            <td class="navigation">
                <a title="Call For Papers" href="cfp">Call For Papers</a>
            </td>
            <td class="navigation">
                <a title="Organizers" href="organization">Organizers</a> 
            </td>
            <td class="navigation">
                <a title="Keynote" href="keynote">Keynote</a>
            </td>
            <td class="navigation">
                <a title="Accepted Papers" href="ap">Accepted Papers</a>
            </td>
            <td class="navigation">
                <a class="current" title="Schedule" href="schedule">Schedule</a>
            </td>
        </tr>
    </table>



<!--     <h2>To Be Announced.</h2> -->

    <h2>Attending Program</h2>
    <h2 style="font-size: 20px"> 2-6pm, Room 134, August 26th, 2024, <a href="https://ccib.es/">Centre de Convencions Internacional de Barcelona</a>, Barcelona, Spain </h2>
    
    <table>
        <tr>
            <td class="date" rowspan="2">
                2:00 – 2:10 pm
            </td>
            <td>
                <strong>Opening Remarks</strong>
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="3">
                2:10 – 2:40 pm
            </td>
            <td>
                <strong>Keynote Talk 1: Uncertainty Quantification in Machine Learning: From Aleatoric to Epistemic </strong> <br>
                <strong>Dr. Eyke Hüllermeier</strong>, Ludwig-Maximilians-Universität München, Germany <br>
                <u>Abstract</u>: Due to the steadily increasing relevance of machine learning for practical applications, many of which are coming with safety requirements, the notion of uncertainty has received increasing attention in machine learning research in the recent past. This talk will address questions regarding the adequate representation and quantification of (predictive) uncertainty in (supervised) machine learning and elaborate on the distinction between two important types of uncertainty, often referred to as aleatoric and epistemic. Roughly speaking, while aleatoric uncertainty is due to the randomness inherent in the data-generating process, epistemic uncertainty is caused by the learner's ignorance of the true underlying model. Bayesian methods are commonly used to quantify both types of uncertainty, but alternative approaches have become popular in recent years, notably so-called evidential deep learning methods. By elaborating on conceptual and theoretical issues of such approaches, the challenging nature of epistemic uncertainty quantification will be elucidated.  
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="3">
                2:40 – 3:40 pm
            </td>
            <td>
                <strong>Accepted Paper Talks 1 </strong>
                <ul>
                    <li style="list-style-type:square"><strong>[Paper ID: 2]</strong> A General Method for Measuring Calibration of Probabilistic Neural Regressors. </li>
                    <li style="list-style-type:square"><strong>[Paper ID: 3]</strong> Flexible Heteroscedastic Count Regression with Deep Double Poisson Networks. </li>
                    <li style="list-style-type:square"><strong>[Paper ID: 5]</strong> Learning Graph Structures and Uncertainty for Accurate and Calibrated Time-series Forecasting. </li>
                    <li style="list-style-type:square"><strong>[Paper ID: 8]</strong> ForeCal: Random Forest-based Calibration for DNNs. </li>
                </ul>
            </td>
        </tr>
    </table>


    <table>
        <tr>
            <td class="date" rowspan="2">
                3:40 – 4:10 pm
            </td>
            <td>
                <strong>Keynote Talk 2</strong> <br>
                <strong>Dr. Yufei Han</strong>, National Institute for Research in Computer Science and Automation, France <br>
                <u>Abstract</u>: The uncertainty in AI-based cyber attack detection mainly comes from the diversity of attacker’s action choices. Attackers may choose different vulnerabilities to exploit, but end up with reaching the same attack goal. The security researchers and service providers have to rely on a set of sources profiling cyber attacks are delivered, including summarizing threat intelligence reports, conducting sandbox analysis, setting up honeypots receiving network traffics. A key question is thus: how to conduct reasoning so that one can draw certain estimation of a system's security status and predict potential threats. In this talk, we will offer a comprehensive introduction to the previous research efforts in uncertainty reasoning techniques deployed in cyber security knowledge encoding and cyber risk prediction.
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="3">
                4:10 – 4:25 pm
            </td>
            <td>
                <strong>Coffee Break </strong>
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="2">
                4:25 – 4:55 pm
            </td>
            <td>
                <strong>Keynote Talk 3</strong> <br>
                <strong>Dr. Meelis Kull</strong>, University of Tartu, Estonia
<!--                 <br>
                <u>Abstract</u>: AI has never been this pervasive and effective. AI algorithms are used in news feeds, friend/purchase recommendation, making hiring and firing decisions, and political campaigns. Data empowers AI algorithms and is then collected again for further training AI algorithms. We come to realize that AI algorithms have biases, and some biases might result in deleterious effects. Facing existential challenges, we explore how socially responsible AI can help in data science: what it is, why it is important, and how it can protect and inform us, and help prevent or mitigate the misuse of AI. We show how socially responsible AI works via use cases of privacy preservation, cyberbullying identification, and disinformation detection. Knowing the problems with AI and our own conflicting goals, we further discuss some quandaries and challenges in our pursuit of socially responsible AI.  -->
            </td>
        </tr>
    </table>

    <table>
        <tr>
            <td class="date" rowspan="3">
                4:55 – 5:55 pm
            </td>
            <td>
                <strong>Accepted Paper Talks 2</strong>
                <ul>
                    <li style="list-style-type:square"><strong>[Paper ID: 10]</strong> Uncertainty-aware segmentation for rainfall prediction post processing. </li>
                    <li style="list-style-type:square"><strong>[Paper ID: 15]</strong> How to Leverage Predictive Uncertainty Estimates for Reducing Catastrophic Forgetting in Online Continual Learning. </li>
                    <li style="list-style-type:square"><strong>[Paper ID: 16]</strong> Measuring Aleatoric and Epistemic Uncertainty in LLMs: Empirical Evaluation on ID and OOD QA Tasks. </li>
                    <li style="list-style-type:square"><strong>[Paper ID: 18]</strong> Bayesian Disease Progression Modeling That Accounts For Health Disparities. </li>
                    
                </ul>
            </td>
        </tr>
    </table>


    <table>
        <tr>
            <td class="date" rowspan="3">
                5:55 – 6:00 pm
            </td>
            <td>
                <strong>Closing</strong>
            </td>
        </tr>
    </table>






    <footer>
        Copyright &copy; 2024 All rights reserved
    </footer>

</body>
</html>

